#!/usr/bin/env python3
"""
è¥¿ç­ç‰™å¤§å­¦æ•°æ®å¯¼å‡ºè„šæœ¬
æ”¯æŒå¯¼å‡ºä¸ºCSVå’ŒExcelæ ¼å¼
"""

import sys
import os
import json
import pandas as pd
from datetime import datetime
from pathlib import Path
import argparse
from typing import List, Dict, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def load_latest_data(data_dir: str = "data") -> List[Dict]:
    """åŠ è½½æœ€æ–°çš„æ•°æ®æ–‡ä»¶"""
    data_path = Path(data_dir)
    
    if not data_path.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return []
    
    # æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    data_files = list(data_path.glob("spain_universities_*.json"))
    
    if not data_files:
        print(f"âŒ åœ¨ {data_dir} ç›®å½•ä¸­æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return []
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(data_files, key=lambda x: x.stat().st_mtime)
    print(f"ğŸ“ æ‰¾åˆ°æœ€æ–°æ•°æ®æ–‡ä»¶: {latest_file}")
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡è®°å½•")
        return data
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
        return []

def clean_data_for_export(data: List[Dict]) -> List[Dict]:
    """æ¸…ç†æ•°æ®ï¼Œå‡†å¤‡å¯¼å‡º"""
    cleaned_data = []
    
    for uni in data:
        # åˆ›å»ºæ¸…ç†åçš„è®°å½•
        cleaned_uni = {
            # åŸºæœ¬ä¿¡æ¯
            "è‹±æ–‡åç§°": uni.get('name_en', ''),
            "æœ¬åœ°åç§°": uni.get('name_local', ''),
            "å›½å®¶": uni.get('country', 'Spain'),
            "åœ°åŒº": uni.get('region', ''),
            "åŸå¸‚": uni.get('city', ''),
            
            # è”ç³»ä¿¡æ¯
            "å®˜æ–¹ç½‘ç«™": uni.get('website', ''),
            "å®˜æ–¹é‚®ç®±": uni.get('official_email', ''),
            "è”ç³»é‚®ç®±": uni.get('contact_email', ''),
            "æ ¡é•¿é‚®ç®±": uni.get('president_email', ''),
            "è¡Œæ”¿é‚®ç®±": uni.get('admin_email', ''),
            "ç”µè¯": uni.get('phone', ''),
            "åœ°å€": uni.get('address', ''),
            
            # åœ°ç†ä¿¡æ¯
            "çº¬åº¦": uni.get('latitude', ''),
            "ç»åº¦": uni.get('longitude', ''),
            
            # åŸºæœ¬ä¿¡æ¯
            "æˆç«‹å¹´ä»½": uni.get('founded_year', ''),
            "å­¦ç”Ÿæ•°é‡": uni.get('student_count', ''),
            "æ•™èŒå·¥æ•°é‡": uni.get('staff_count', ''),
            "å¤§å­¦ç±»å‹": uni.get('university_type', ''),
            "è®¤è¯æœºæ„": uni.get('accreditation', ''),
            
            # æ’åä¿¡æ¯
            "å›½å†…æ’å": uni.get('ranking_national', ''),
            "ä¸–ç•Œæ’å": uni.get('ranking_world', ''),
            
            # å…ƒæ•°æ®
            "æ•°æ®æ¥æº": uni.get('data_source', ''),
            "æœ€åéªŒè¯æ—¶é—´": uni.get('last_verified', ''),
            "å¤‡æ³¨": uni.get('notes', '')
        }
        
        cleaned_data.append(cleaned_uni)
    
    return cleaned_data

def export_to_csv(data: List[Dict], output_dir: str = "data/exports") -> str:
    """å¯¼å‡ºä¸ºCSVæ ¼å¼"""
    if not data:
        print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
        return ""
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"spain_universities_{timestamp}.csv"
    filepath = os.path.join(output_dir, filename)
    
    try:
        # å¯¼å‡ºä¸ºCSV
        df.to_csv(filepath, index=False, encoding='utf-8-sig')  # ä½¿ç”¨utf-8-sigæ”¯æŒä¸­æ–‡
        print(f"âœ… CSVæ–‡ä»¶å·²å¯¼å‡º: {filepath}")
        print(f"   è®°å½•æ•°é‡: {len(data)}")
        print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(filepath) / 1024:.1f} KB")
        return filepath
    except Exception as e:
        print(f"âŒ CSVå¯¼å‡ºå¤±è´¥: {str(e)}")
        return ""

def export_to_excel(data: List[Dict], output_dir: str = "data/exports") -> str:
    """å¯¼å‡ºä¸ºExcelæ ¼å¼"""
    if not data:
        print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
        return ""
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"spain_universities_{timestamp}.xlsx"
    filepath = os.path.join(output_dir, filename)
    
    try:
        # åˆ›å»ºExcelå†™å…¥å™¨
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            # ä¸»æ•°æ®è¡¨
            df.to_excel(writer, sheet_name='å¤§å­¦æ•°æ®', index=False)
            
            # ç»Ÿè®¡ä¿¡æ¯è¡¨
            stats_data = generate_statistics(data)
            stats_df = pd.DataFrame(stats_data)
            stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡ä¿¡æ¯', index=False)
            
            # åœ°åŒºåˆ†å¸ƒè¡¨
            region_data = generate_region_stats(data)
            region_df = pd.DataFrame(region_data)
            region_df.to_excel(writer, sheet_name='åœ°åŒºåˆ†å¸ƒ', index=False)
            
            # åŸå¸‚åˆ†å¸ƒè¡¨
            city_data = generate_city_stats(data)
            city_df = pd.DataFrame(city_data)
            city_df.to_excel(writer, sheet_name='åŸå¸‚åˆ†å¸ƒ', index=False)
        
        print(f"âœ… Excelæ–‡ä»¶å·²å¯¼å‡º: {filepath}")
        print(f"   è®°å½•æ•°é‡: {len(data)}")
        print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(filepath) / 1024:.1f} KB")
        print(f"   åŒ…å«å·¥ä½œè¡¨: å¤§å­¦æ•°æ®, ç»Ÿè®¡ä¿¡æ¯, åœ°åŒºåˆ†å¸ƒ, åŸå¸‚åˆ†å¸ƒ")
        return filepath
    except Exception as e:
        print(f"âŒ Excelå¯¼å‡ºå¤±è´¥: {str(e)}")
        return ""

def generate_statistics(data: List[Dict]) -> List[Dict]:
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
    total_count = len(data)
    with_official_email = len([u for u in data if u.get('å®˜æ–¹é‚®ç®±')])
    with_president_email = len([u for u in data if u.get('æ ¡é•¿é‚®ç®±')])
    with_admin_email = len([u for u in data if u.get('è¡Œæ”¿é‚®ç®±')])
    with_ranking = len([u for u in data if u.get('ä¸–ç•Œæ’å')])
    
    # æŒ‰å¤§å­¦ç±»å‹ç»Ÿè®¡
    public_count = len([u for u in data if 'public' in u.get('å¤§å­¦ç±»å‹', '').lower()])
    private_count = len([u for u in data if 'private' in u.get('å¤§å­¦ç±»å‹', '').lower()])
    
    stats = [
        {"ç»Ÿè®¡é¡¹ç›®": "æ€»å¤§å­¦æ•°é‡", "æ•°å€¼": total_count},
        {"ç»Ÿè®¡é¡¹ç›®": "æœ‰å®˜æ–¹é‚®ç®±", "æ•°å€¼": with_official_email, "ç™¾åˆ†æ¯”": f"{with_official_email/total_count*100:.1f}%"},
        {"ç»Ÿè®¡é¡¹ç›®": "æœ‰æ ¡é•¿é‚®ç®±", "æ•°å€¼": with_president_email, "ç™¾åˆ†æ¯”": f"{with_president_email/total_count*100:.1f}%"},
        {"ç»Ÿè®¡é¡¹ç›®": "æœ‰è¡Œæ”¿é‚®ç®±", "æ•°å€¼": with_admin_email, "ç™¾åˆ†æ¯”": f"{with_admin_email/total_count*100:.1f}%"},
        {"ç»Ÿè®¡é¡¹ç›®": "æœ‰ä¸–ç•Œæ’å", "æ•°å€¼": with_ranking, "ç™¾åˆ†æ¯”": f"{with_ranking/total_count*100:.1f}%"},
        {"ç»Ÿè®¡é¡¹ç›®": "å…¬ç«‹å¤§å­¦", "æ•°å€¼": public_count, "ç™¾åˆ†æ¯”": f"{public_count/total_count*100:.1f}%"},
        {"ç»Ÿè®¡é¡¹ç›®": "ç§ç«‹å¤§å­¦", "æ•°å€¼": private_count, "ç™¾åˆ†æ¯”": f"{private_count/total_count*100:.1f}%"},
    ]
    
    return stats

def generate_region_stats(data: List[Dict]) -> List[Dict]:
    """ç”Ÿæˆåœ°åŒºåˆ†å¸ƒç»Ÿè®¡"""
    regions = {}
    for uni in data:
        region = uni.get('åœ°åŒº', 'æœªçŸ¥')
        regions[region] = regions.get(region, 0) + 1
    
    region_stats = []
    for region, count in sorted(regions.items(), key=lambda x: x[1], reverse=True):
        region_stats.append({
            "åœ°åŒº": region,
            "å¤§å­¦æ•°é‡": count,
            "å æ¯”": f"{count/len(data)*100:.1f}%"
        })
    
    return region_stats

def generate_city_stats(data: List[Dict]) -> List[Dict]:
    """ç”ŸæˆåŸå¸‚åˆ†å¸ƒç»Ÿè®¡"""
    cities = {}
    for uni in data:
        city = uni.get('åŸå¸‚', 'æœªçŸ¥')
        cities[city] = cities.get(city, 0) + 1
    
    city_stats = []
    for city, count in sorted(cities.items(), key=lambda x: x[1], reverse=True):
        city_stats.append({
            "åŸå¸‚": city,
            "å¤§å­¦æ•°é‡": count,
            "å æ¯”": f"{count/len(data)*100:.1f}%"
        })
    
    return city_stats

def print_data_summary(data: List[Dict]):
    """æ‰“å°æ•°æ®æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®æ‘˜è¦")
    print("="*60)
    
    total_count = len(data)
    print(f"æ€»å¤§å­¦æ•°é‡: {total_count}")
    
    # é‚®ç®±ç»Ÿè®¡
    with_official = len([u for u in data if u.get('å®˜æ–¹é‚®ç®±')])
    with_president = len([u for u in data if u.get('æ ¡é•¿é‚®ç®±')])
    with_admin = len([u for u in data if u.get('è¡Œæ”¿é‚®ç®±')])
    
    print(f"æœ‰å®˜æ–¹é‚®ç®±: {with_official} ({with_official/total_count*100:.1f}%)")
    print(f"æœ‰æ ¡é•¿é‚®ç®±: {with_president} ({with_president/total_count*100:.1f}%)")
    print(f"æœ‰è¡Œæ”¿é‚®ç®±: {with_admin} ({with_admin/total_count*100:.1f}%)")
    
    # åœ°åŒºåˆ†å¸ƒ
    regions = {}
    for uni in data:
        region = uni.get('åœ°åŒº', 'æœªçŸ¥')
        regions[region] = regions.get(region, 0) + 1
    
    print(f"\nåœ°åŒºåˆ†å¸ƒ (å‰5):")
    for region, count in sorted(regions.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"  {region}: {count}")
    
    # åŸå¸‚åˆ†å¸ƒ
    cities = {}
    for uni in data:
        city = uni.get('åŸå¸‚', 'æœªçŸ¥')
        cities[city] = cities.get(city, 0) + 1
    
    print(f"\nåŸå¸‚åˆ†å¸ƒ (å‰5):")
    for city, count in sorted(cities.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"  {city}: {count}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¯¼å‡ºè¥¿ç­ç‰™å¤§å­¦æ•°æ®')
    parser.add_argument('--format', choices=['csv', 'excel', 'both'], default='both',
                       help='å¯¼å‡ºæ ¼å¼ (é»˜è®¤: both)')
    parser.add_argument('--data-dir', default='data',
                       help='æ•°æ®ç›®å½• (é»˜è®¤: data)')
    parser.add_argument('--output-dir', default='data/exports',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: data/exports)')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ“¤ è¥¿ç­ç‰™å¤§å­¦æ•°æ®å¯¼å‡ºå·¥å…·")
    print("="*60)
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“ åŠ è½½æ•°æ®...")
    data = load_latest_data(args.data_dir)
    
    if not data:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®ï¼Œç¨‹åºé€€å‡º")
        sys.exit(1)
    
    # æ¸…ç†æ•°æ®
    print("\nğŸ§¹ æ¸…ç†æ•°æ®...")
    cleaned_data = clean_data_for_export(data)
    
    # æ‰“å°æ•°æ®æ‘˜è¦
    print_data_summary(cleaned_data)
    
    # å¯¼å‡ºæ•°æ®
    print(f"\nğŸ“¤ å¯¼å‡ºæ•°æ® (æ ¼å¼: {args.format})...")
    
    exported_files = []
    
    if args.format in ['csv', 'both']:
        csv_file = export_to_csv(cleaned_data, args.output_dir)
        if csv_file:
            exported_files.append(csv_file)
    
    if args.format in ['excel', 'both']:
        excel_file = export_to_excel(cleaned_data, args.output_dir)
        if excel_file:
            exported_files.append(excel_file)
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("âœ… å¯¼å‡ºå®Œæˆ!")
    print("="*60)
    
    for file in exported_files:
        print(f"ğŸ“„ {file}")
    
    print(f"\nğŸ’¡ æç¤º:")
    print(f"   - CSVæ–‡ä»¶å¯ä»¥ç”¨Excelæ‰“å¼€")
    print(f"   - Excelæ–‡ä»¶åŒ…å«å¤šä¸ªå·¥ä½œè¡¨")
    print(f"   - å»ºè®®å®šæœŸå¤‡ä»½å¯¼å‡ºçš„æ•°æ®")

if __name__ == "__main__":
    main() 